import glob

import hanlp
import os

"""
* åˆå§‹åŒ–è¨“ç·´
# åŠ é€Ÿ (INTEL)
pip install --upgrade intel-tensorflow
"""
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # åªé¡¯ç¤º Error
from hanlp.components.ner.transformer_ner import TransformerNamedEntityRecognizer

# å®šç¾©è¨“ç·´æª”æ¡ˆå’Œåˆä½µæª”æ¡ˆè·¯å¾‘
train_files = glob.glob('../data/train/source_*.txt')
merged_train_file = '../data/train/merged_train.txt'

# è‡ªå‹•åˆä½µæª”æ¡ˆ
with open(merged_train_file, 'w', encoding='utf-8') as outfile:
    for train_file in train_files:
        with open(train_file, 'r', encoding='utf-8') as infile:
            outfile.write(infile.read())
            outfile.write('\n')  # ç¢ºä¿æª”æ¡ˆé–“æ›è¡Œåˆ†éš”

# è¨“ç·´æ¨¡å‹
recognizer = TransformerNamedEntityRecognizer()
save_dir = '../data/model/ner/product_bert'

recognizer.fit(
    trn_data=merged_train_file,  # ä½¿ç”¨åˆä½µå¾Œçš„æª”æ¡ˆ
    dev_data='../data/train/dev.txt',
    save_dir=save_dir,
    transformer='bert-base-chinese',
    # bert-base-chinese æˆ– electra-small (CPUæ…¢), å¯é¸: 1.FINE_ELECTRA_SMALL_ZH MSRA_NER_ELECTRA_SMALL_ZH
    epochs=10,
    batch_size=8,
    word_dropout=0.05,
    delimiter_in_entity='-',
    char_level=True  # ğŸ‘ˆ åŠ é€™å€‹
)

recognizer = hanlp.load(save_dir)
test_sentences = 'æŸ¥è¯¢åšå£«ä¼¦-XY99åº“å­˜'
results = recognizer.predict(test_sentences)
print(results)
